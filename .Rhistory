p_val <- pt(test_stat, df, lower.tail = TRUE)
if(alternative == "greater")
p_val <- 1 - p_val
else if(alternative == "two.sided")
p_val <- min(p_val, 1 - p_val) * 2
return(
list("test_stat" = test_stat,
"df" = df,
"alternative" = alternative,
"p_val" = p_val)
)
}
# sample data
sample <- rnorm(17, mean = 0, sd = 1)
my_t.test(sample, "two.sided", 1)
t.test(sample, mu = 1, alternative = "two.sided")
my_t.test(sample, "greater", .8)
t.test(sample, mu = .8, alternative = "greater")
# takes a formula and data as parameters and outputs a linear regression summary
my_lm <- function(formula, data) {
x <- model.matrix(formula, data)
y <- model.response(model.frame(formula, data))
beta <- solve(t(x) %*% x) %*% t(x) %*% y
df <- nrow(x) - ncol(x)
variance <- 0
for(i in 1:nrow(x)) {
variance <- variance +
(y[i] - x[i, ] %*% beta)^2 / df
}
se <- sqrt(diag(solve(t(x) %*% x) * variance[1,1]))
t <- beta / se
pr <- pt(abs(t), 30, lower.tail = FALSE) * 2
report <- data.frame("estimate" = beta[1],
"se" = se[1],
"t" = t[1],
"pr" = as.character(pr[1]))
for(i in 2:ncol(x)) {
report <- rbind(report,
data.frame("estimate" = beta[i],
"se" = se[i],
"t" = t[i],
"pr" = as.character(pr[i]))
)
}
# return(
#   kable_styling(
#     knitr::kable(report,
#                  col.names = c("Estimate",
#                                "Std. Error",
#                                "t value",
#                                "Pr(>|t|)")
#                  )
#     )
# )
return(report)
}
my_lm(mpg ~ wt, mtcars)
summary(lm(mpg ~ wt, mtcars))
mtcars
my_lm(mpg ~ wt + cl, mtcars)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(kableExtra)
# function that takes in a vector of data, a parameter that indicates a one or two tailed test, and a hypothesized mean and calculates a t-value and p-value
my_t.test <- function(x, alternative, mu) {
if(!(alternative %in% c("two.sided", "less", "greater")))
stop("Parameter \"alternative\" must equal \"two.sided\", \"less\", or \"greater\"")
df <- length(x) - 1
se <- sd(x) / sqrt(length(x))
test_stat <- (mean(x) - mu) / se
p_val <- pt(test_stat, df, lower.tail = TRUE)
if(alternative == "greater")
p_val <- 1 - p_val
else if(alternative == "two.sided")
p_val <- min(p_val, 1 - p_val) * 2
return(
list("test_stat" = test_stat,
"df" = df,
"alternative" = alternative,
"p_val" = p_val)
)
}
# sample data
sample <- rnorm(17, mean = 0, sd = 1)
my_t.test(sample, "two.sided", 1)
t.test(sample, mu = 1, alternative = "two.sided")
my_t.test(sample, "greater", .8)
t.test(sample, mu = .8, alternative = "greater")
# takes a formula and data as parameters and outputs a linear regression summary
my_lm <- function(formula, data) {
x <- model.matrix(formula, data)
y <- model.response(model.frame(formula, data))
beta <- solve(t(x) %*% x) %*% t(x) %*% y
df <- nrow(x) - ncol(x)
variance <- 0
for(i in 1:nrow(x)) {
variance <- variance +
(y[i] - x[i, ] %*% beta)^2 / df
}
se <- sqrt(diag(solve(t(x) %*% x) * variance[1,1]))
t <- beta / se
pr <- pt(abs(t), 30, lower.tail = FALSE) * 2
report <- data.frame("estimate" = beta[1],
"se" = se[1],
"t" = t[1],
"pr" = as.character(pr[1]))
for(i in 2:ncol(x)) {
report <- rbind(report,
data.frame("estimate" = beta[i],
"se" = se[i],
"t" = t[i],
"pr" = as.character(pr[i]))
)
}
# return(
#   kable_styling(
#     knitr::kable(report,
#                  col.names = c("Estimate",
#                                "Std. Error",
#                                "t value",
#                                "Pr(>|t|)")
#                  )
#     )
# )
return(report)
}
my_lm(mpg ~ wt, mtcars)
summary(lm(mpg ~ wt, mtcars))
my_lm(mpg ~ wt + cyl, mtcars)
penguins[complete.cases(penguins), ]
# remove rows with NA, corresponding to missing data
p_data <- penguins %>% drop_na()
penguins[complete.cases(penguins), ]
# function takes in a data frame, class to predict, number of neighbors, and number of folds
# outputs a vector of the predicted class the error from the true class values
my_knn_cv <- function(train, cl, k_nn, k_cv) {
fold <- sample(rep(1:k_cv, length = nrow(train)))
train <- train %>% mutate("split" = fold)
predict_matrix <- data.frame("cl" = train[, which(names(train) == cl)],
"err" = c(1:nrow(train)*0))
for(i in 1:k_cv) {
# define training and test data and predict using knn algorithm
data_train <- train %>% filter(split != i)
data_test <- train %>% filter(split == i)
predict <- knn(data.frame(data_train[, -which(names(data_train) == cl)]),
data.frame(data_test[, -which(names(data_test) == cl)]),
as.vector(data_train %>% pull(cl)),
k_nn)
# find which rows of the original dataset the predicted values correspond to
predict_rows <- match(c(1:nrow(data_test)), match(do.call("paste", train[, colnames(train)]), do.call("paste", data_test[, colnames(train)])))
# build output class vector and define error
for(j in 1:length(predict_rows)) {
predict_matrix[predict_rows[j], 1] <- predict[j]
if(predict_matrix[predict_rows[j], 1] != train[predict_rows[j], ] %>% pull(cl))
predict_matrix[predict_rows[j], 2] <- 1
}
}
cv_err <- sum(predict_matrix$err) / nrow(predict_matrix)
class <- predict_matrix %>% pull(cl)
return(list(cv_err, class))
}
my_knn_cv(p_data[, c(1, 3:6)], "species", 5, 5)
# remove rows with NA, corresponding to missing data
p_data <- penguins[complete.cases(penguins), ]
# function takes in a data frame, class to predict, number of neighbors, and number of folds
# outputs a vector of the predicted class the error from the true class values
my_knn_cv <- function(train, cl, k_nn, k_cv) {
fold <- sample(rep(1:k_cv, length = nrow(train)))
train <- train %>% mutate("split" = fold)
predict_matrix <- data.frame("cl" = train[, which(names(train) == cl)],
"err" = c(1:nrow(train)*0))
for(i in 1:k_cv) {
# define training and test data and predict using knn algorithm
data_train <- train %>% filter(split != i)
data_test <- train %>% filter(split == i)
predict <- knn(data.frame(data_train[, -which(names(data_train) == cl)]),
data.frame(data_test[, -which(names(data_test) == cl)]),
as.vector(data_train %>% pull(cl)),
k_nn)
# find which rows of the original dataset the predicted values correspond to
predict_rows <- match(c(1:nrow(data_test)), match(do.call("paste", train[, colnames(train)]), do.call("paste", data_test[, colnames(train)])))
# build output class vector and define error
for(j in 1:length(predict_rows)) {
predict_matrix[predict_rows[j], 1] <- predict[j]
if(predict_matrix[predict_rows[j], 1] != train[predict_rows[j], ] %>% pull(cl))
predict_matrix[predict_rows[j], 2] <- 1
}
}
cv_err <- sum(predict_matrix$err) / nrow(predict_matrix)
class <- predict_matrix %>% pull(cl)
return(list(cv_err, class))
}
my_knn_cv(p_data[, c(1, 3:6)], "species", 5, 5)
# remove rows with NA, corresponding to missing data
p_data <- penguins %>% drop_na()
# function takes in a data frame, class to predict, number of neighbors, and number of folds
# outputs a vector of the predicted class the error from the true class values
my_knn_cv <- function(train, cl, k_nn, k_cv) {
fold <- sample(rep(1:k_cv, length = nrow(train)))
train <- train %>% mutate("split" = fold)
predict_matrix <- data.frame("cl" = train[, which(names(train) == cl)],
"err" = c(1:nrow(train)*0))
for(i in 1:k_cv) {
# define training and test data and predict using knn algorithm
data_train <- train %>% filter(split != i)
data_test <- train %>% filter(split == i)
predict <- knn(data.frame(data_train[, -which(names(data_train) == cl)]),
data.frame(data_test[, -which(names(data_test) == cl)]),
as.vector(data_train %>% pull(cl)),
k_nn)
# find which rows of the original dataset the predicted values correspond to
predict_rows <- match(c(1:nrow(data_test)), match(do.call("paste", train[, colnames(train)]), do.call("paste", data_test[, colnames(train)])))
# build output class vector and define error
for(j in 1:length(predict_rows)) {
predict_matrix[predict_rows[j], 1] <- predict[j]
if(predict_matrix[predict_rows[j], 1] != train[predict_rows[j], ] %>% pull(cl))
predict_matrix[predict_rows[j], 2] <- 1
}
}
cv_err <- sum(predict_matrix$err) / nrow(predict_matrix)
class <- predict_matrix %>% pull(cl)
return(list(cv_err, class))
}
my_knn_cv(p_data[, c(1, 3:6)], "species", 5, 5)
# remove rows with NA, corresponding to missing data
p_data <- penguins[complete.cases(penguins), ]
# function takes in a data frame, class to predict, number of neighbors, and number of folds
# outputs a vector of the predicted class the error from the true class values
my_knn_cv <- function(train, cl, k_nn, k_cv) {
fold <- sample(rep(1:k_cv, length = nrow(train)))
train <- train %>% mutate("split" = fold)
predict_matrix <- data.frame("cl" = train[, which(names(train) == cl)],
"err" = c(1:nrow(train)*0))
for(i in 1:k_cv) {
# define training and test data and predict using knn algorithm
data_train <- train %>% filter(split != i)
data_test <- train %>% filter(split == i)
predict <- knn(data.frame(data_train[, -which(names(data_train) == cl)]),
data.frame(data_test[, -which(names(data_test) == cl)]),
as.vector(data_train %>% pull(cl)),
k_nn)
# find which rows of the original dataset the predicted values correspond to
predict_rows <- match(c(1:nrow(data_test)), match(do.call("paste", train[, colnames(train)]), do.call("paste", data_test[, colnames(train)])))
# build output class vector and define error
for(j in 1:length(predict_rows)) {
predict_matrix[predict_rows[j], 1] <- predict[j]
if(predict_matrix[predict_rows[j], 1] != train[predict_rows[j], ] %>% pull(cl))
predict_matrix[predict_rows[j], 2] <- 1
}
}
cv_err <- sum(predict_matrix$err) / nrow(predict_matrix)
class <- predict_matrix %>% pull(cl)
return(list(cv_err, class))
}
my_knn_cv(p_data[, c(1, 3:6)], "species", 5, 5)
knitr::opts_chunk$set(echo = TRUE)
library(palmerpenguins)
library(dplyr)
library(class)
library(tidyverse)
library(randomForest)
library(kableExtra)
data(package = "palmerpenguins")
# remove rows with NA, corresponding to missing data
p_data <- penguins[complete.cases(penguins), ]
# function takes in a data frame, class to predict, number of neighbors, and number of folds
# outputs a vector of the predicted class the error from the true class values
my_knn_cv <- function(train, cl, k_nn, k_cv) {
fold <- sample(rep(1:k_cv, length = nrow(train)))
train <- train %>% mutate("split" = fold)
predict_matrix <- data.frame("cl" = train[, which(names(train) == cl)],
"err" = c(1:nrow(train)*0))
for(i in 1:k_cv) {
# define training and test data and predict using knn algorithm
data_train <- train %>% filter(split != i)
data_test <- train %>% filter(split == i)
predict <- knn(data.frame(data_train[, -which(names(data_train) == cl)]),
data.frame(data_test[, -which(names(data_test) == cl)]),
as.vector(data_train %>% pull(cl)),
k_nn)
# find which rows of the original dataset the predicted values correspond to
predict_rows <- match(c(1:nrow(data_test)), match(do.call("paste", train[, colnames(train)]), do.call("paste", data_test[, colnames(train)])))
# build output class vector and define error
for(j in 1:length(predict_rows)) {
predict_matrix[predict_rows[j], 1] <- predict[j]
if(predict_matrix[predict_rows[j], 1] != train[predict_rows[j], ] %>% pull(cl))
predict_matrix[predict_rows[j], 2] <- 1
}
}
cv_err <- sum(predict_matrix$err) / nrow(predict_matrix)
class <- predict_matrix %>% pull(cl)
return(list(cv_err, class))
}
my_knn_cv(p_data[, c(1, 3:6)], "species", 5, 5)
err_table <- data.frame("1nn" = my_knn_cv(p_data[, c(1, 3:6)], "species", 1, 5)[[1]],
"5nn" = my_knn_cv(p_data[, c(1, 3:6)], "species", 5, 5)[[1]])
kable_styling(knitr::kable(err_table, col.names = c("CV error for 1-nearest neighbor", "CV error for 5-nearest neighbor")))
# function takes in the number of folds and outputs the cv error when applying the random forest algorithm to predict body mass
my_rf_cv <- function(k) {
train <- p_data[, c(3:6)]
cl <- "body_mass_g"
fold <- sample(rep(1:k, length = nrow(train)))
train <- train %>% mutate("split" = fold)
predict_matrix <- data.frame("cl" = train[, which(names(train) == cl)],
"err" = c(1:nrow(train)*0))
mse <- c(1:k)
for(i in 1:k) {
# define training and test data and predict using random forest algorithm
data_train <- train %>% filter(split != i)
data_test <- train %>% filter(split == i)
model <- randomForest(body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm, data = data_train, ntree = 100)
prediction <- predict(model, data_test[, 1:3])
# calculate mean squared error for current fold
fold_sum <- 0
for(j in 1:nrow(data_test)) {
fold_sum <- fold_sum + (data_test[j, ] %>% pull(4) - prediction[[j]])^2
}
mse[i] <- fold_sum / nrow(data_test)
}
# calculate cv error
cv <- sum(mse) / k
return(cv)
}
# function takes in the number of folds and outputs the cv error when applying the random forest algorithm to predict body mass
my_rf_cv <- function(k) {
train <- p_data[, c(3:6)]
cl <- "body_mass_g"
fold <- sample(rep(1:k, length = nrow(train)))
train <- train %>% mutate("split" = fold)
predict_matrix <- data.frame("cl" = train[, which(names(train) == cl)],
"err" = c(1:nrow(train)*0))
mse <- c(1:k)
for(i in 1:k) {
# define training and test data and predict using random forest algorithm
data_train <- train %>% filter(split != i)
data_test <- train %>% filter(split == i)
model <- randomForest(body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm, data = data_train, ntree = 100)
prediction <- predict(model, data_test[, 1:3])
# calculate mean squared error for current fold
fold_sum <- 0
for(j in 1:nrow(data_test)) {
fold_sum <- fold_sum + (data_test[j, ] %>% pull(4) - prediction[[j]])^2
}
mse[i] <- fold_sum / nrow(data_test)
}
# calculate cv error
cv <- sum(mse) / k
return(cv)
}
my_rf_cv(5)
library(devtools)
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
library(stat302package)
setwd("~/Stat 302/STAT302/projects/project3/stat302package")
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
library(stat302package)
devtools::install()
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
library(stat302package)
my_lm(lifeExp ~ gdpPercap + continent, my_gapminder)
my_knn_cv(my_penguins[complete.cases(my_penguins), c(1, 3:6)], "species", 5, 5)
df <- data.frame(k_nn = 1, cv_error = my_knn_cv(my_penguins[complete.cases(my_penguins), c(1, 3:6)], "species", 1, 5)[[1]])
for(i in 2:10) {
df <- rbind(df, data.frame(data.frame(k_nn = i, cv_error = my_knn_cv(my_penguins[complete.cases(my_penguins), c(1, 3:6)], "species", i, 5)[[1]])))
}
df
usethis::use+test("my_t.test")
usethis::use_test("my_t.test")
my_t.test(my_gapminder$lifeExp, "two.sided", 60)
expect_equal(my_t.test(my_gapminder$lifeExp, "two.sided", 60)$test_stat
my_t.test(my_gapminder$lifeExp, "two.sided", 60)$test_stat
my_t.test(my_gapminder$lifeExp, "two.sided", 60)
my_t.test(my_gapminder$lifeExp, "two.sided", 60)[[test_stat]]
my_t.test(my_gapminder$lifeExp, "two.sided", 60)[test_stat]
my_t.test(my_gapminder$lifeExp, "two.sided", 60)["test_stat"]
expect_equal(my_t.test(my_gapminder$lifeExp, "two.sided", 60)["test_stat"], -1.679548)
library(testthat)
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat.R', echo=TRUE)
test_that("t-test works", {
expect_equal(my_t.test(my_gapminder$lifeExp, "two.sided", 60)["test_stat"], -1.679548)
})
my_t.test(my_gapminder$lifeExp, "two.sided", 60)["test_stat"]
expect_equal(my_t.test(my_gapminder$lifeExp, "two.sided", 60)[["test_stat"]], -1.679548)
test_that("t-test works", {
expect_equal(my_t.test(my_gapminder$lifeExp, "two.sided", 60)[["test_stat"]], -1.679548)
})
my_t.test(my_gapminder$lifeExp, "two.sided", 60)[["test_stat"]]
my_t.test(my_gapminder$lifeExp, "two.sided", 60)[["test_stat"]]
my_t.test(my_gapminder$lifeExp, "two.sided", 60)[["test_stat"]]
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_t.R', echo=TRUE)
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_t.R', echo=TRUE)
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_t.R', echo=TRUE)
my_t.test(my_gapminder$lifeExp, "two.sided", 60)["test_stat"]
my_t.test(my_gapminder$lifeExp, "two.sided", 60)
my_t.test(my_gapminder$lifeExp, "two.sided", 60)["test_stat"]
(my_t.test(c(1:120), "two.sided", 60)[["test_stat"]]
my_t.test(c(1:120), "two.sided", 60)[["test_stat"]]
my_t.test(c(1:120), "two.sided", 60)
my_t.test(c(1:120), "two.sided", 60)
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_t.R', echo=TRUE)
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_t.R', echo=TRUE)
expect_equal(my_t.test(c(1:120), "two.sided", 60)[["test_stat"]], 0.1574592)
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_t.R', echo=TRUE)
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_t.R', echo=TRUE)
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_t.R', echo=TRUE)
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_t.R', echo=TRUE)
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_t.R', echo=TRUE)
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_t.R', echo=TRUE)
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_t.R', echo=TRUE)
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_t.R', echo=TRUE)
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_t.R', echo=TRUE)
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_t.R', echo=TRUE)
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_t.R', echo=TRUE)
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_t.R', echo=TRUE)
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_t.R', echo=TRUE)
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_t.R', echo=TRUE)
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_t.R', echo=TRUE)
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_t.R', echo=TRUE)
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_t.R', echo=TRUE)
usethis::use_test("my_lm")
my_lm(lifeExp ~ gdpPercap + continent, my_gapminder)
my_lm(lifeExp ~ gdpPercap + continent, my_gapminder)[1, ]
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_lm.R', echo=TRUE)
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_lm.R', echo=TRUE)
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_lm.R', echo=TRUE)
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_lm.R', echo=TRUE)
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_lm.R', echo=TRUE)
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_lm.R', echo=TRUE)
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_lm.R', echo=TRUE)
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_lm.R', echo=TRUE)
6.87097209465118*10^-44.
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_lm.R', echo=TRUE)
my_lm(lifeExp ~ gdpPercap + continent, my_gapminder)[1, 4]
my_lm(lifeExp ~ gdpPercap + continent, my_gapminder)[1, 4]
my_lm(lifeExp ~ gdpPercap + continent, my_gapminder)[1, 4][[1]]
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_lm.R', echo=TRUE)
my_knn_cv(my_penguins[complete.cases(my_penguins), c(1, 3:6)], "species", 5, 5)
my_knn_cv(my_penguins[complete.cases(my_penguins), c(1, 3:6)], "species", 5, 5)[[1]]
my_knn_cv(my_penguins[complete.cases(my_penguins), c(1, 3:6)], "species", 5, 5)[[1]]
my_knn_cv(my_penguins[complete.cases(my_penguins), c(1, 3:6)], "species", 5, 5)
my_knn_cv(my_penguins[complete.cases(my_penguins), c(1, 3:6)], "species", 5, 5)[[1]]
my_knn_cv(my_penguins[complete.cases(my_penguins), c(1, 3:6)], "species", 5, 5)[[1]]
my_knn_cv(my_penguins[complete.cases(my_penguins), c(1, 3:6)], "species", 5, 5)[[1]]
my_knn_cv(my_penguins[complete.cases(my_penguins), c(1, 3:6)], "species", 5, 5)[[1]]
my_knn_cv(data.frame("a" = c(1:5), "b" = c(1:5), "c" = c(1:5)), "a", 5, 5)[[1]]
my_knn_cv(data.frame("a" = c(1:5), "b" = c(1:5), "c" = c(1:5)), "a", 5, 5)[[1]]
my_knn_cv(data.frame("a" = c(1:50), "b" = c(1:50), "c" = c(1:50)), "a", 5, 5)[[1]]
my_knn_cv(data.frame("a" = c(1:50), "b" = c(1:50), "c" = c(1:50)), "a", 5, 5)[[1]]
my_knn_cv(my_penguins[complete.cases(my_penguins), c(1, 3:6)], "species", 5, 5)
my_knn_cv(data.frame("a" = c(1:50), "b" = c(1:50), "c" = c(1:50)), "a", 5, 5)[[1]]
my_knn_cv(data.frame("a" = c(1:50), "b" = c(1:50), "c" = c(1:50)), "a", 5, 5)[[1]]
my_knn_cv(data.frame("a" = c(1:50), "b" = c(1:50), "c" = c(1:50)), "a", 5, 5)[[1]]
my_knn_cv(data.frame("a" = c(1:50), "b" = c(1:50), "c" = c(1:50)), "a", 5, 5)[[1]]
my_knn_cv(data.frame("a" = c(1:50), "b" = c(1:50), "c" = c(1:50)), "a", 5, 5)[[1]]
my_knn_cv(data.frame("a" = c(1:50), "b" = c(1:50), "c" = c(1:50)), "a", 5, 5)[[1]]
my_knn_cv(data.frame("a" = c(1:50), "b" = c(1:50), "c" = c(1:50)), "a", 5, 5)[[1]]
usethis::use_test("my_knn_cv")
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_knn_cv.R', echo=TRUE)
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_knn_cv.R', echo=TRUE)
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_knn_cv.R', echo=TRUE)
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_knn_cv.R', echo=TRUE)
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_knn_cv.R', echo=TRUE)
expect_equal(my_knn_cv(data.frame("a" = c(1:50), "b" = c(1:50), "c" = c(1:50)), "a", 5, 5)[[1]], c(.9, .91, .92, .93, .94, .95, .96, .97, .98, .99))
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_knn_cv.R', echo=TRUE)
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_knn_cv.R', echo=TRUE)
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_knn_cv.R', echo=TRUE)
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_knn_cv.R', echo=TRUE)
my_knn_cv(data.frame("a" = c(1:50), "b" = c(1:50), "c" = c(1:50)), "a", 5, 5)[[2]]
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_knn_cv.R', echo=TRUE)
usethis::use_test("my_rf_cv")
my_rf_cv(5)
expect_equal(my_rf_cv(5), 119406.2)
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_rf_cv.R', echo=TRUE)
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_rf_cv.R', echo=TRUE)
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_rf_cv.R', echo=TRUE)
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_lm.R', echo=TRUE)
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_lm.R', echo=TRUE)
source('~/Stat 302/STAT302/projects/project3/stat302package/tests/testthat/test-my_t.R', echo=TRUE)
devtools::check()
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
library(stat302package)
my_lm(lifeExp ~ gdpPercap + continent, my_gapminder)
my_knn_cv(my_penguins[complete.cases(my_penguins), c(1, 3:6)], "species", 5, 5)
df <- data.frame(k_nn = 1, cv_error = my_knn_cv(my_penguins[complete.cases(my_penguins), c(1, 3:6)], "species", 1, 5)[[1]])
for(i in 2:10) {
df <- rbind(df, data.frame(data.frame(k_nn = i, cv_error = my_knn_cv(my_penguins[complete.cases(my_penguins), c(1, 3:6)], "species", i, 5)[[1]])))
}
df
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
library(stat302package)
my_lm(lifeExp ~ gdpPercap + continent, my_gapminder)
my_knn_cv(my_penguins[complete.cases(my_penguins), c(1, 3:6)], "species", 5, 5)
df <- data.frame(k_nn = 1, cv_error = my_knn_cv(my_penguins[complete.cases(my_penguins), c(1, 3:6)], "species", 1, 5)[[1]])
for(i in 2:10) {
df <- rbind(df, data.frame(data.frame(k_nn = i, cv_error = my_knn_cv(my_penguins[complete.cases(my_penguins), c(1, 3:6)], "species", i, 5)[[1]])))
}
df
